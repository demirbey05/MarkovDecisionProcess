{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from robot import RecycleEnv\n",
    "class MonteCarloAgent:\n",
    "    def __init__(self,env,gamma=0.9,theta=0.01):\n",
    "        self.name = \"Monte Carlo Agent\"\n",
    "        self.env = env\n",
    "        self.V = {\"low\": 0, \"high\": 0}\n",
    "        self.pi = {\"low\": self.env.getPossibleActions(\"low\"), \"high\": self.env.getPossibleActions(\"high\")}\n",
    "        self.gamma = gamma\n",
    "        self.theta = theta\n",
    "\n",
    "    \n",
    "    def estimate_value_monte_carlo(self,n = 1000):\n",
    "        episode = []\n",
    "        # generate an episode\n",
    "        for i in range(n):\n",
    "            action = random.choice(self.pi[self.env.state])\n",
    "            prev_state = self.env.state\n",
    "            _, reward,_,_,_ = self.env.step(action)\n",
    "            episode.append((prev_state,reward)) # s_i, r_i+1\n",
    "\n",
    "        # calculate the return\n",
    "        encountered_states = []\n",
    "        returns = {\"low\": [], \"high\": []}\n",
    "\n",
    "        G = 0\n",
    "        for i in episode:\n",
    "            G = self.gamma * G + i[1]\n",
    "            if i[0] not in encountered_states:\n",
    "                returns[i[0]].append(G)\n",
    "                encountered_states.append(i[0])\n",
    "                self.V[i[0]] = sum(returns[i[0]])/len(returns[i[0]])\n",
    "\n",
    "    def policy_evaluation(self):\n",
    "        states = [\"low\", \"high\"]\n",
    "\n",
    "        while True:\n",
    "            delta = 0\n",
    "            for state in states:\n",
    "                v = self.V[state]\n",
    "                value = self.calculate_state_value(state)\n",
    "                self.V[state] = value\n",
    "                delta = max(delta, abs(v - self.V[state]))\n",
    "\n",
    "            if delta < self.theta:\n",
    "                break\n",
    "    \n",
    "    def calculate_state_value(self,state):\n",
    "        actions = self.pi[state]\n",
    "        value = 0\n",
    "        for action in actions:\n",
    "            value += (1/len(actions)) *self.calculate_q_value(state,action)\n",
    "        return value/len(actions)\n",
    "\n",
    "\n",
    "    def calculate_q_value(self,state,action):\n",
    "        sum = 0\n",
    "        for transition in self.env.getTransitionStatesandProbs(state, action):\n",
    "            next_state, reward, prob, _ = transition\n",
    "            sum += prob * (reward + self.gamma * self.V[next_state])\n",
    "        return sum\n",
    "    def reset_values(self):\n",
    "        self.V = {\"low\": 0, \"high\": 0}\n",
    "\n",
    "env = RecycleEnv()\n",
    "agent = MonteCarloAgent(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'low': 10.84, 'high': 4.0}\n",
      "{'low': 0, 'high': 0}\n"
     ]
    }
   ],
   "source": [
    "agent.estimate_value_monte_carlo(3000)\n",
    "print(agent.V)\n",
    "agent.reset_values()\n",
    "print(agent.V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'low': 0.31796212481061953, 'high': 1.9367127407122717}\n"
     ]
    }
   ],
   "source": [
    "agent.policy_evaluation()\n",
    "print(agent.V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
